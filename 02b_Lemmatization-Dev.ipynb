{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project: Improving NLTK's Lemmatization Process\n",
    "\n",
    "Submitted by Shannon Bingham\n",
    "February 2019\n",
    "\n",
    "\n",
    "## Executive Summary\n",
    "The Natural Language Toolkit (NLTK) is a widely used open source solution for computer processing and analysis of human language.  The toolkit includes many useful utilities including an interface to the WordNet lexical reference database.  When I used the toolkit's stemming and lemmatizing programs for a Natural Language Processing (NLP) classification project at General Assembly, I grew very curious about first, the data that was being created, and second, the logic going on under the hood.  My questions led me to wonder about how I could improve the quality of my input data, especially given that the sheer number of features in an NLP project makes it quite challenging to understand what the data looks like.\n",
    "\n",
    "For my capstone project, I decided to improve the NLTK interface to WordNet.  My work on this project led to many interesting insights about electronic dictionaries as well as about language processing in general.  Over the course of  project, I became more deeply interested in NLP, an area in data science that is growing rapidly.  The changes that I made to the toolkit built a foundation that provides greater control over the lemmatization process and, thus, more opportunity to improve data.  The changes will be available for implementation anywhere.\n",
    "\n",
    "## Notebook Description\n",
    "This notebook includes all the code I used to run and time the lemmatization process using my own version of the NLTK stem and corpus reader versions of wordnet.py.  This notebook was executed in a special Jupyter environment that I set up to include my modules in the sys.path.  Please note the Setup cell that drives the variables substitutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Setup"
    ]
   },
   "source": [
    "### Set up environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "Setup"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/homefolder/anaconda3/envs/mynltk/lib/python36.zip',\n",
       " '/Users/homefolder/anaconda3/envs/mynltk/lib/python3.6',\n",
       " '/Users/homefolder/anaconda3/envs/mynltk/lib/python3.6/lib-dynload',\n",
       " '',\n",
       " '/Users/homefolder/anaconda3/envs/mynltk/lib/python3.6/site-packages',\n",
       " '/Users/homefolder/anaconda3/envs/mynltk/lib/python3.6/site-packages/IPython/extensions',\n",
       " '/Users/homefolder/.ipython']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify correct libraries for the dev environment.\n",
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "Setup"
    ]
   },
   "outputs": [],
   "source": [
    "# Import libraries and modules.\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Import Natural Language Toolkit modules.\n",
    "from nltk.stem     import WordNetLemmatizer\n",
    "\n",
    "# Increase number of columns that can be viewed in notebook.\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "# Set random seed for reproducibility.\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "Setup"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** The tokenized  data will be loaded from \"./data/tokens_s10000.csv\". **\n",
      "\n",
      "** The lemmatized data will be saved in    \"./data/lemmas_dev_s10000.csv\". **\n",
      "\n",
      "** The elapsed time data will be saved in  \"./data/lemmas_dev_s10000_time.csv\". **\n"
     ]
    }
   ],
   "source": [
    "# Specify the number of reviews of each type (pos and neg) being sampled.\n",
    "n = 5000\n",
    "\n",
    "# Specify whether the lemmas were created by the prod version of WordNet (True or False).\n",
    "prod = False\n",
    "if prod:\n",
    "    env = 'prod'\n",
    "else:\n",
    "    env = 'dev'\n",
    "\n",
    "# Set file location for input file.\n",
    "tokens_csv = (f'./data/tokens_s{n*2}.csv')\n",
    "\n",
    "# Set file location for output files.\n",
    "lemmas_csv = (f'./data/lemmas_{env}_s{n*2}.csv')\n",
    "time_csv   = (f'./data/lemmas_{env}_s{n*2}_time.csv')\n",
    "\n",
    "# Print messages.\n",
    "print(f'** The tokenized  data will be loaded from \"{tokens_csv}\". **')\n",
    "print()\n",
    "print(f'** The lemmatized data will be saved in    \"{lemmas_csv}\". **')\n",
    "print()\n",
    "print(f'** The elapsed time data will be saved in  \"{time_csv}\". **')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Setup"
    ]
   },
   "source": [
    "### Load data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "Setup"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>sergio martino is the case of the scorpion is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>this is a very good made for tv film it depict...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>this is not a love song is a brilliant example...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>i must admit at first i was not expecting anyt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>those individuals familiar with asian cinema a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                             tokens\n",
       "0      1  sergio martino is the case of the scorpion is ...\n",
       "1      1  this is a very good made for tv film it depict...\n",
       "2      1  this is not a love song is a brilliant example...\n",
       "3      1  i must admit at first i was not expecting anyt...\n",
       "4      1  those individuals familiar with asian cinema a..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data.\n",
    "df = pd.read_csv(tokens_csv)\n",
    "\n",
    "# Take a look.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "Setup"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9986 entries, 0 to 9985\n",
      "Data columns (total 2 columns):\n",
      "label     9986 non-null int64\n",
      "tokens    9986 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 156.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the data.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'able', 'about', 'above', 'across']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the snapwords.\n",
    "snapwords_file = (f'./data/snapwords')\n",
    "\n",
    "with open(snapwords_file, 'r') as f:\n",
    "          data=f.read().replace('\\n', ' ')\n",
    "\n",
    "# Convert the string to a list.        \n",
    "snapwords = data.split()\n",
    "\n",
    "# Take a look.\n",
    "snapwords[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the local_dictionary.\n",
    "dictionary_file = (f'./data/local_dictionary')\n",
    "\n",
    "local_dict = {}\n",
    "    \n",
    "with open(dictionary_file, 'r') as f:\n",
    "          for line in f:\n",
    "            (key, val) = line.split()\n",
    "            local_dict[(key)] = val\n",
    "\n",
    "# Verify load.\n",
    "len(local_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "NLPreprocessing"
    ]
   },
   "source": [
    "## Lemmatization \n",
    "\n",
    "**Process:** \n",
    "\n",
    "- Lemmatize the tokens:\n",
    "    - Use the WordNet development version to obtain lemmas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total elapsed time processing lemmatization was  22.91330099105835\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>sergio martino is the case of the scorpion is ...</td>\n",
       "      <td>sergio martino be the case of the scorpion be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>this is a very good made for tv film it depict...</td>\n",
       "      <td>this be a very good make for tv film it depict...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>this is not a love song is a brilliant example...</td>\n",
       "      <td>this be not a love song be a brilliant example...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>i must admit at first i was not expecting anyt...</td>\n",
       "      <td>i must admit at first i be not expect anything...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>those individuals familiar with asian cinema a...</td>\n",
       "      <td>those individual familiar with asian cinema as...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                             tokens  \\\n",
       "0      1  sergio martino is the case of the scorpion is ...   \n",
       "1      1  this is a very good made for tv film it depict...   \n",
       "2      1  this is not a love song is a brilliant example...   \n",
       "3      1  i must admit at first i was not expecting anyt...   \n",
       "4      1  those individuals familiar with asian cinema a...   \n",
       "\n",
       "                                              lemmas  \n",
       "0  sergio martino be the case of the scorpion be ...  \n",
       "1  this be a very good make for tv film it depict...  \n",
       "2  this be not a love song be a brilliant example...  \n",
       "3  i must admit at first i be not expect anything...  \n",
       "4  those individual familiar with asian cinema as...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get time at beginning of lemmatization.\n",
    "t_begin = time.time()\n",
    "\n",
    "# Instantiate Lemmatizer.\n",
    "lemmatizer = WordNetLemmatizer(snap_words=snapwords,\n",
    "                               local_dictionary=local_dict,\n",
    "                               remember_words=True)\n",
    "\n",
    "# Initialize list for elapsed time data.\n",
    "time_data = []\n",
    "\n",
    "# Loop through the dataframe.\n",
    "for i in range(df.shape[0]):\n",
    "    \n",
    "    # Start the clock.\n",
    "    t0 = time.time()\n",
    "   \n",
    "    # Lemmatize words.\n",
    "    lemmas = [lemmatizer.lemmatize(w, multiple_pos_calls=['v', 'r', 'a', 'n']) \n",
    "              for w in df.iloc[i]['tokens'].split()]\n",
    "    \n",
    "    # Stop the clock.\n",
    "    t_end = time.time()\n",
    "    \n",
    "    # Save results.\n",
    "    time_data.append([len(lemmas), (t_end - t0)]) \n",
    "    \n",
    "    # Join the lemmas back into a single string and save it.\n",
    "    df.loc[i,'lemmas'] = \" \".join(lemmas) \n",
    "\n",
    "print('Total elapsed time processing lemmatization was ',(time.time() - t_begin))\n",
    "    \n",
    "# Take a look.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Type                    Number      Hits % Total\n",
      "--------------------------------------------------\n",
      "snapwords                  807   1342413   57.10\n",
      "local dictionary            16     20799    0.90\n",
      "remembered words         50131    936467   39.90\n",
      "* not cached *               0     50131    2.10\n",
      "\n",
      "Total                            2349810\n"
     ]
    }
   ],
   "source": [
    "# Get results from the Lemmatizer.\n",
    "lemmatizer.lemmatize(' ', print_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "NLPreprocessing"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>sergio martino be the case of the scorpion be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>this be a very good make for tv film it depict...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>this be not a love song be a brilliant example...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>i must admit at first i be not expect anything...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>those individual familiar with asian cinema as...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                             lemmas\n",
       "0      1  sergio martino be the case of the scorpion be ...\n",
       "1      1  this be a very good make for tv film it depict...\n",
       "2      1  this be not a love song be a brilliant example...\n",
       "3      1  i must admit at first i be not expect anything...\n",
       "4      1  those individual familiar with asian cinema as..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only needed columns.\n",
    "df = df[['label', 'lemmas']]\n",
    "\n",
    "# Verify update.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "NLPreprocessing"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma count</th>\n",
       "      <th>elapsed_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>410</td>\n",
       "      <td>1.491192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>190</td>\n",
       "      <td>0.001078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>264</td>\n",
       "      <td>0.001067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150</td>\n",
       "      <td>0.000679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>528</td>\n",
       "      <td>0.001806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lemma count  elapsed_time\n",
       "0          410      1.491192\n",
       "1          190      0.001078\n",
       "2          264      0.001067\n",
       "3          150      0.000679\n",
       "4          528      0.001806"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the time data.\n",
    "time_df = pd.DataFrame(time_data, columns=['lemma count', 'elapsed_time'])\n",
    "\n",
    "# Take a look.\n",
    "time_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Wrapup"
    ]
   },
   "source": [
    "### Save data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "Wrapup"
    ]
   },
   "outputs": [],
   "source": [
    "# Save the NLP data.\n",
    "df.to_csv(lemmas_csv, encoding='utf-8', index=False)\n",
    "\n",
    "# Save the elapsed time data.\n",
    "time_df.to_csv(time_csv, encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
